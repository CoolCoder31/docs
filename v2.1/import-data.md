---
title: Import Data
summary: Learn how to import data into a CockroachDB cluster.
toc: true
---

CockroachDB supports importing data from CSV/TSV or SQL dump files.

{{site.data.alerts.callout_info}}To import/restore data from CockroachDB-generated <a href="backup.html">enterprise license backups</a>, see <a href="restore.html"><code>RESTORE</code></a>.{{site.data.alerts.end}}

## Import from tabular data (CSV)

If you have data exported in a tabular format (e.g., CSV or TSV), you can use the [`IMPORT`](import.html) statement.

To use this statement, though, you must also have some kind of remote file server (such as Amazon S3 or a custom file server) that all your nodes can access.

## Import from generic SQL dump

You can execute batches of `INSERT` statements stored in `.sql` files (including those generated by [`cockroach dump`](sql-dump.html)) from the command line, importing data into your cluster.

{% include copy-clipboard.html %}
~~~ shell
$ cockroach sql --database=[database name] < statements.sql
~~~

{{site.data.alerts.callout_success}}Grouping each <code>INSERT</code> statement to include approximately 500-10,000 rows will provide the best performance. The number of rows depends on row size, column families, number of indexes; smaller rows and less complex schemas can benefit from larger groups of <code>INSERTS</code>, while larger rows and more complex schemas benefit from smaller groups.{{site.data.alerts.end}}

## See also

- [`IMPORT`](import.html)
- [SQL Dump (Export)](sql-dump.html)
- [Back up Data](back-up-data.html)
- [Restore Data](restore-data.html)
- [Use the Built-in SQL Client](use-the-built-in-sql-client.html)
- [Other Cockroach Commands](cockroach-commands.html)
